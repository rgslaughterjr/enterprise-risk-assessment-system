{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enterprise Risk Assessment System - Interactive Demo\n",
    "\n",
    "**Production Multi-Agent AI System for Automated Cybersecurity Risk Assessment**\n",
    "\n",
    "This notebook demonstrates the complete capabilities of the system across Weeks 1-12:\n",
    "\n",
    "- **Week 6:** Multi-agent orchestration (ServiceNow, Vulnerability, Threat, Risk Scoring, Report)\n",
    "- **Week 7:** Advanced RAG pipeline and Document Intelligence\n",
    "- **Week 9:** Control discovery and gap analysis\n",
    "- **Week 10:** Tree of Thought (ToT) risk scoring\n",
    "- **Week 11:** Markov Chain threat modeling\n",
    "- **Week 12:** AWS deployment architecture\n",
    "\n",
    "---\n",
    "\n",
    "## Table of Contents\n",
    "1. [Setup & Configuration](#setup)\n",
    "2. [Week 6: Core Multi-Agent System](#week6)\n",
    "3. [Week 7: RAG & Document Intelligence](#week7)\n",
    "4. [Week 9: Control Discovery & Gap Analysis](#week9)\n",
    "5. [Week 10: Tree of Thought Risk Scoring](#week10)\n",
    "6. [Week 11: Markov Chain Threat Modeling](#week11)\n",
    "7. [Visualizations & Insights](#visualizations)\n",
    "8. [Complete Workflow Demo](#workflow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='setup'></a>\n",
    "## 1. Setup & Configuration\n",
    "\n",
    "First, let's install dependencies and configure the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages (uncomment if needed)\n",
    "# !pip install -r ../requirements.txt\n",
    "\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Add project root to path\n",
    "project_root = Path.cwd().parent\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "# Load environment variables\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(project_root / '.env')\n",
    "\n",
    "# Verify key environment variables\n",
    "required_vars = ['ANTHROPIC_API_KEY', 'SERVICENOW_INSTANCE']\n",
    "missing = [v for v in required_vars if not os.getenv(v)]\n",
    "if missing:\n",
    "    print(f\"‚ö†Ô∏è  Missing environment variables: {missing}\")\n",
    "    print(\"Please configure .env file with required API keys\")\n",
    "else:\n",
    "    print(\"‚úÖ Environment configured successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import visualization libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configure matplotlib for notebook\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"‚úÖ Visualization libraries loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='week6'></a>\n",
    "## 2. Week 6: Core Multi-Agent System\n",
    "\n",
    "Demonstrates the 6 core agents:\n",
    "1. ServiceNow Agent - Query incidents and assets\n",
    "2. Vulnerability Agent - Analyze CVEs with NVD, VirusTotal, CISA KEV\n",
    "3. Threat Agent - MITRE ATT&CK and AlienVault OTX intelligence\n",
    "4. Risk Scoring Agent - FAIR-based 5√ó5 matrix\n",
    "5. Report Agent - Professional DOCX generation\n",
    "6. Document Agent - RAG-based policy/procedure queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 ServiceNow Agent - Query Incidents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.agents.servicenow_agent import ServiceNowAgent\n",
    "\n",
    "# Initialize agent\n",
    "snow_agent = ServiceNowAgent()\n",
    "\n",
    "# Query high-priority incidents\n",
    "incidents = snow_agent.get_incidents_for_analysis(\n",
    "    priority=\"1\",\n",
    "    limit=5\n",
    ")\n",
    "\n",
    "print(f\"Found {len(incidents)} high-priority incidents:\")\n",
    "for inc in incidents:\n",
    "    print(f\"  ‚Ä¢ {inc.number}: {inc.short_description} (Priority {inc.priority})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Vulnerability Agent - CVE Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.agents.vulnerability_agent import VulnerabilityAgent\n",
    "\n",
    "vuln_agent = VulnerabilityAgent()\n",
    "\n",
    "# Analyze critical CVEs\n",
    "cve_ids = [\"CVE-2024-3400\", \"CVE-2024-21762\"]\n",
    "analyses = vuln_agent.analyze_cves(cve_ids)\n",
    "\n",
    "for analysis in analyses:\n",
    "    cve = analysis.cve_detail\n",
    "    exp = analysis.exploitation_status\n",
    "    \n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"CVE: {cve.cve_id}\")\n",
    "    print(f\"CVSS: {cve.cvss_score} ({cve.cvss_severity})\")\n",
    "    print(f\"Priority Score: {analysis.priority_score}/100\")\n",
    "    print(f\"CISA KEV: {'YES ‚ö†Ô∏è' if exp.in_cisa_kev else 'No'}\")\n",
    "    print(f\"VirusTotal Detections: {exp.vt_detections}\")\n",
    "    print(f\"\\nDescription: {cve.description[:200]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Threat Agent - MITRE ATT&CK Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.agents.threat_agent import ThreatAgent\n",
    "\n",
    "threat_agent = ThreatAgent()\n",
    "\n",
    "# Analyze threat landscape for CVE-2024-3400 (Palo Alto PAN-OS)\n",
    "threat_intel = threat_agent.analyze_cve_threat(\n",
    "    cve_id=\"CVE-2024-3400\",\n",
    "    vulnerability_type=\"OS command injection\"\n",
    ")\n",
    "\n",
    "print(f\"Threat Intelligence for CVE-2024-3400:\")\n",
    "print(f\"\\nMapped MITRE ATT&CK Techniques ({len(threat_intel.techniques)}):\")\n",
    "for tech in threat_intel.techniques[:5]:\n",
    "    print(f\"  ‚Ä¢ {tech.technique_id}: {tech.name}\")\n",
    "\n",
    "print(f\"\\nIndicators of Compromise ({len(threat_intel.iocs)}):\")\n",
    "for ioc in threat_intel.iocs[:3]:\n",
    "    print(f\"  ‚Ä¢ {ioc.type}: {ioc.value}\")\n",
    "\n",
    "print(f\"\\nThreat Narrative:\\n{threat_intel.narrative[:300]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Risk Scoring Agent - FAIR 5√ó5 Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.agents.risk_scoring_agent import RiskScoringAgent\n",
    "\n",
    "risk_agent = RiskScoringAgent()\n",
    "\n",
    "# Calculate risk for CVE-2024-3400 on production firewall\n",
    "risk_rating = risk_agent.calculate_risk(\n",
    "    cve_id=\"CVE-2024-3400\",\n",
    "    asset_name=\"firewall-prod-01\",\n",
    "    cvss_score=10.0,\n",
    "    in_cisa_kev=True,\n",
    "    asset_criticality=5,\n",
    "    data_sensitivity=5,\n",
    "    business_impact=5,\n",
    "    compliance_impact=4\n",
    ")\n",
    "\n",
    "print(f\"\\nRisk Assessment Results:\")\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"Asset: {risk_rating.asset_name}\")\n",
    "print(f\"CVE: {risk_rating.cve_id}\")\n",
    "print(f\"\\nLikelihood: {risk_rating.likelihood}/5\")\n",
    "print(f\"Impact: {risk_rating.impact}/5\")\n",
    "print(f\"\\nRisk Score: {risk_rating.score}/25\")\n",
    "print(f\"Risk Level: {risk_rating.level} {'üî¥' if risk_rating.level == 'Critical' else 'üü°'}\")\n",
    "print(f\"\\nJustification:\\n{risk_rating.justification}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='week7'></a>\n",
    "## 3. Week 7: RAG & Document Intelligence\n",
    "\n",
    "Demonstrates advanced RAG pipeline and document processing capabilities:\n",
    "- Semantic chunking (5 strategies)\n",
    "- Hybrid retrieval (BM25 + semantic)\n",
    "- Query optimization\n",
    "- OCR processing\n",
    "- Table extraction\n",
    "- Document classification\n",
    "- Entity extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Semantic Chunking Strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.tools.semantic_chunker import SemanticChunker\n",
    "\n",
    "# Sample policy document\n",
    "sample_policy = \"\"\"\n",
    "Access Control Policy v2.1\n",
    "\n",
    "1. Purpose\n",
    "This policy establishes requirements for managing user access to information systems.\n",
    "\n",
    "2. Scope\n",
    "Applies to all employees, contractors, and third-party users accessing company systems.\n",
    "\n",
    "3. Authentication Requirements\n",
    "3.1 Multi-Factor Authentication (MFA)\n",
    "All users must enable MFA for access to production systems. MFA must use at least two \n",
    "of the following factors: something you know (password), something you have (token), \n",
    "something you are (biometric).\n",
    "\n",
    "3.2 Password Requirements\n",
    "Passwords must be at least 12 characters, including uppercase, lowercase, numbers, \n",
    "and special characters. Passwords expire every 90 days.\n",
    "\n",
    "4. Authorization\n",
    "Access is granted based on principle of least privilege. Managers must review user \n",
    "access quarterly and certify appropriateness.\n",
    "\"\"\"\n",
    "\n",
    "chunker = SemanticChunker()\n",
    "\n",
    "# Compare chunking strategies\n",
    "strategies = ['fixed', 'sentence', 'paragraph', 'semantic']\n",
    "results = {}\n",
    "\n",
    "for strategy in strategies:\n",
    "    chunks = chunker.chunk_text(sample_policy, strategy=strategy, chunk_size=200)\n",
    "    results[strategy] = chunks\n",
    "    print(f\"\\n{strategy.upper()} Strategy: {len(chunks)} chunks\")\n",
    "    print(f\"Sample chunk: {chunks[0]['text'][:100]}...\")\n",
    "\n",
    "# Visualize chunk sizes\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "for strategy, chunks in results.items():\n",
    "    sizes = [len(c['text']) for c in chunks]\n",
    "    ax.plot(sizes, marker='o', label=strategy)\n",
    "\n",
    "ax.set_xlabel('Chunk Index')\n",
    "ax.set_ylabel('Chunk Size (characters)')\n",
    "ax.set_title('Chunking Strategy Comparison')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Hybrid Retrieval (BM25 + Semantic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.tools.hybrid_retriever import HybridRetriever\n",
    "\n",
    "# Initialize retriever and add document chunks\n",
    "retriever = HybridRetriever()\n",
    "semantic_chunks = results['semantic']\n",
    "retriever.add_documents(semantic_chunks)\n",
    "\n",
    "# Test queries\n",
    "queries = [\n",
    "    \"What are the MFA requirements?\",\n",
    "    \"How often should passwords be changed?\",\n",
    "    \"Who needs to review user access?\"\n",
    "]\n",
    "\n",
    "print(\"Hybrid Retrieval Results (0.9 semantic + 0.1 BM25):\\n\")\n",
    "for query in queries:\n",
    "    results = retriever.retrieve(\n",
    "        query=query,\n",
    "        top_k=2,\n",
    "        semantic_weight=0.9,\n",
    "        keyword_weight=0.1\n",
    "    )\n",
    "    \n",
    "    print(f\"Query: '{query}'\")\n",
    "    print(f\"Top result (score: {results[0]['score']:.3f}):\")\n",
    "    print(f\"  {results[0]['text'][:150]}...\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Query Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.tools.query_optimizer import QueryOptimizer\n",
    "\n",
    "optimizer = QueryOptimizer()\n",
    "\n",
    "# Original query\n",
    "original = \"authentication controls\"\n",
    "\n",
    "# Expand query with synonyms\n",
    "expanded = optimizer.expand_query(original)\n",
    "print(f\"Original: {original}\")\n",
    "print(f\"Expanded: {expanded}\")\n",
    "\n",
    "# Rewrite query for better retrieval\n",
    "rewritten = optimizer.rewrite_query(\n",
    "    original,\n",
    "    \"You are searching a cybersecurity policy database\"\n",
    ")\n",
    "print(f\"\\nRewritten: {rewritten}\")\n",
    "\n",
    "# Generate hypothetical document (HyDE)\n",
    "hyde = optimizer.generate_hypothetical_document(original)\n",
    "print(f\"\\nHyDE (Hypothetical Document):\")\n",
    "print(f\"{hyde[:200]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Document Classification & Entity Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.tools.document_classifier import DocumentClassifier\n",
    "from src.tools.entity_extractor import EntityExtractor\n",
    "\n",
    "# Classify document type\n",
    "classifier = DocumentClassifier()\n",
    "classifier.train([{\n",
    "    'text': sample_policy,\n",
    "    'category': 'policy_document'\n",
    "}])\n",
    "doc_type = classifier.classify(sample_policy)\n",
    "print(f\"Document Type: {doc_type}\")\n",
    "\n",
    "# Extract entities\n",
    "extractor = EntityExtractor()\n",
    "\n",
    "# Sample text with entities\n",
    "entity_text = \"\"\"\n",
    "Critical vulnerability CVE-2024-3400 affects asset firewall-prod-01.\n",
    "NIST control AC-2 (Account Management) is not properly implemented.\n",
    "Risk rating: HIGH - requires immediate remediation per NIST 800-53.\n",
    "\"\"\"\n",
    "\n",
    "entities = extractor.extract_entities(entity_text)\n",
    "\n",
    "print(\"\\nExtracted Entities:\")\n",
    "for entity_type, items in entities.items():\n",
    "    if items:\n",
    "        print(f\"  {entity_type}: {items}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='week9'></a>\n",
    "## 4. Week 9: Control Discovery & Gap Analysis\n",
    "\n",
    "Demonstrates automated control discovery from multiple sources and gap analysis against risk requirements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.agents.control_discovery_agent import ControlDiscoveryAgent\n",
    "from src.tools.gap_analyzer import GapAnalyzer\n",
    "\n",
    "# Initialize control discovery agent\n",
    "control_agent = ControlDiscoveryAgent()\n",
    "\n",
    "# Discover controls from multiple sources\n",
    "discovered_controls = control_agent.discover_controls(\n",
    "    sources=['servicenow_grc', 'confluence', 'filesystem'],\n",
    "    control_frameworks=['NIST_800_53', 'ISO_27001']\n",
    ")\n",
    "\n",
    "print(f\"Discovered {len(discovered_controls)} controls:\")\n",
    "for ctrl in discovered_controls[:5]:\n",
    "    print(f\"  ‚Ä¢ {ctrl['control_id']}: {ctrl['title']}\")\n",
    "    print(f\"    Source: {ctrl['source']} | Status: {ctrl['implementation_status']}\")\n",
    "\n",
    "# Gap analysis\n",
    "gap_analyzer = GapAnalyzer()\n",
    "\n",
    "# Required controls for high-risk CVE\n",
    "required_controls = [\n",
    "    'AC-2',  # Account Management\n",
    "    'AC-3',  # Access Enforcement\n",
    "    'SI-2',  # Flaw Remediation\n",
    "    'RA-5',  # Vulnerability Scanning\n",
    "    'CA-7',  # Continuous Monitoring\n",
    "]\n",
    "\n",
    "gaps = gap_analyzer.analyze_gaps(\n",
    "    required_controls=required_controls,\n",
    "    implemented_controls=[c['control_id'] for c in discovered_controls]\n",
    ")\n",
    "\n",
    "print(f\"\\nGap Analysis Results:\")\n",
    "print(f\"  Coverage: {gaps['coverage_percentage']:.1f}%\")\n",
    "print(f\"  Missing Controls: {gaps['missing_controls']}\")\n",
    "print(f\"  Partially Implemented: {gaps['partial_controls']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Control Coverage Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create control coverage visualization\n",
    "control_families = {\n",
    "    'AC': 'Access Control',\n",
    "    'AU': 'Audit and Accountability',\n",
    "    'CA': 'Assessment and Authorization',\n",
    "    'SI': 'System and Information Integrity',\n",
    "    'RA': 'Risk Assessment',\n",
    "    'SC': 'System and Communications Protection'\n",
    "}\n",
    "\n",
    "# Simulate coverage data\n",
    "coverage_data = pd.DataFrame({\n",
    "    'Family': list(control_families.values()),\n",
    "    'Implemented': [12, 8, 6, 10, 7, 9],\n",
    "    'Partial': [3, 4, 2, 3, 2, 3],\n",
    "    'Missing': [2, 3, 4, 2, 3, 2]\n",
    "})\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "coverage_data.set_index('Family')[['Implemented', 'Partial', 'Missing']].plot(\n",
    "    kind='bar',\n",
    "    stacked=True,\n",
    "    ax=ax,\n",
    "    color=['#2ecc71', '#f39c12', '#e74c3c']\n",
    ")\n",
    "ax.set_title('NIST 800-53 Control Coverage by Family', fontsize=14, fontweight='bold')\n",
    "ax.set_xlabel('Control Family')\n",
    "ax.set_ylabel('Number of Controls')\n",
    "ax.legend(title='Status')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Calculate overall coverage percentage\n",
    "total = coverage_data[['Implemented', 'Partial', 'Missing']].sum().sum()\n",
    "implemented = coverage_data['Implemented'].sum() + coverage_data['Partial'].sum() * 0.5\n",
    "coverage_pct = (implemented / total) * 100\n",
    "print(f\"\\nOverall Control Coverage: {coverage_pct:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='week10'></a>\n",
    "## 5. Week 10: Tree of Thought (ToT) Risk Scoring\n",
    "\n",
    "Demonstrates multi-branch risk evaluation using Tree of Thought reasoning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.agents.tot_risk_scorer import ToTRiskScorer\n",
    "\n",
    "tot_scorer = ToTRiskScorer()\n",
    "\n",
    "# Evaluate risk using ToT with multiple reasoning paths\n",
    "tot_result = tot_scorer.evaluate_risk_with_tot(\n",
    "    cve_id=\"CVE-2024-3400\",\n",
    "    asset_name=\"firewall-prod-01\",\n",
    "    cvss_score=10.0,\n",
    "    in_cisa_kev=True,\n",
    "    asset_criticality=5,\n",
    "    num_thoughts=3,  # Generate 3 reasoning paths\n",
    "    depth=2  # 2-level reasoning tree\n",
    ")\n",
    "\n",
    "print(\"Tree of Thought Risk Scoring Results:\")\n",
    "print(f\"{'='*70}\\n\")\n",
    "print(f\"Evaluated {len(tot_result['thoughts'])} reasoning paths:\\n\")\n",
    "\n",
    "for i, thought in enumerate(tot_result['thoughts'], 1):\n",
    "    print(f\"Path {i}: {thought['path']}\")\n",
    "    print(f\"  Risk Score: {thought['risk_score']}/25\")\n",
    "    print(f\"  Confidence: {thought['confidence']:.2f}\")\n",
    "    print(f\"  Reasoning: {thought['reasoning'][:100]}...\\n\")\n",
    "\n",
    "print(f\"Final Aggregated Risk Score: {tot_result['final_score']}/25\")\n",
    "print(f\"Recommendation: {tot_result['recommendation']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ToT Reasoning Tree Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize ToT reasoning paths\n",
    "thoughts_df = pd.DataFrame([\n",
    "    {'Path': t['path'], 'Score': t['risk_score'], 'Confidence': t['confidence']}\n",
    "    for t in tot_result['thoughts']\n",
    "])\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Risk scores by path\n",
    "thoughts_df.plot(x='Path', y='Score', kind='bar', ax=ax1, legend=False, color='coral')\n",
    "ax1.set_title('Risk Scores by Reasoning Path', fontweight='bold')\n",
    "ax1.set_ylabel('Risk Score (0-25)')\n",
    "ax1.set_xlabel('Reasoning Path')\n",
    "ax1.axhline(y=tot_result['final_score'], color='red', linestyle='--', label='Final Score')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Confidence levels\n",
    "thoughts_df.plot(x='Path', y='Confidence', kind='bar', ax=ax2, legend=False, color='skyblue')\n",
    "ax2.set_title('Confidence by Reasoning Path', fontweight='bold')\n",
    "ax2.set_ylabel('Confidence (0-1)')\n",
    "ax2.set_xlabel('Reasoning Path')\n",
    "ax2.set_ylim(0, 1)\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='week11'></a>\n",
    "## 6. Week 11: Markov Chain Threat Modeling\n",
    "\n",
    "Demonstrates probabilistic threat scenario generation using Markov Chains based on MITRE ATT&CK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.agents.threat_scenario_agent import ThreatScenarioAgent\n",
    "from src.tools.attack_transition_builder import AttackTransitionBuilder\n",
    "\n",
    "# Initialize threat scenario agent\n",
    "scenario_agent = ThreatScenarioAgent()\n",
    "\n",
    "# Generate attack scenarios using Markov Chain\n",
    "scenarios = scenario_agent.generate_scenarios(\n",
    "    initial_technique=\"T1190\",  # Exploit Public-Facing Application\n",
    "    num_scenarios=3,\n",
    "    max_steps=5\n",
    ")\n",
    "\n",
    "print(\"Markov Chain Threat Scenarios:\")\n",
    "print(f\"{'='*70}\\n\")\n",
    "\n",
    "for i, scenario in enumerate(scenarios, 1):\n",
    "    print(f\"Scenario {i}: {scenario['name']}\")\n",
    "    print(f\"Probability: {scenario['probability']:.2%}\")\n",
    "    print(f\"Attack Path:\")\n",
    "    \n",
    "    for step in scenario['attack_path']:\n",
    "        print(f\"  {step['step']}. {step['technique_id']}: {step['technique_name']}\")\n",
    "        print(f\"     Tactic: {step['tactic']} | Transition Prob: {step['transition_prob']:.2%}\")\n",
    "    \n",
    "    print(f\"\\nNarrative: {scenario['narrative'][:200]}...\")\n",
    "    print(f\"\\nRecommended Controls: {', '.join(scenario['recommended_controls'][:3])}\")\n",
    "    print(f\"\\n{'‚îÄ'*70}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attack Path Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "\n",
    "# Build attack graph from scenarios\n",
    "G = nx.DiGraph()\n",
    "\n",
    "for scenario in scenarios:\n",
    "    path = scenario['attack_path']\n",
    "    for i in range(len(path) - 1):\n",
    "        current = path[i]['technique_id']\n",
    "        next_tech = path[i + 1]['technique_id']\n",
    "        prob = path[i + 1]['transition_prob']\n",
    "        G.add_edge(current, next_tech, weight=prob)\n",
    "\n",
    "# Visualize attack graph\n",
    "fig, ax = plt.subplots(figsize=(14, 10))\n",
    "pos = nx.spring_layout(G, k=2, iterations=50)\n",
    "\n",
    "# Draw nodes\n",
    "nx.draw_networkx_nodes(G, pos, node_color='lightcoral', \n",
    "                       node_size=3000, alpha=0.9, ax=ax)\n",
    "\n",
    "# Draw edges with varying thickness based on probability\n",
    "edges = G.edges()\n",
    "weights = [G[u][v]['weight'] * 5 for u, v in edges]\n",
    "nx.draw_networkx_edges(G, pos, width=weights, alpha=0.6, \n",
    "                       edge_color='gray', arrows=True, \n",
    "                       arrowsize=20, ax=ax)\n",
    "\n",
    "# Draw labels\n",
    "nx.draw_networkx_labels(G, pos, font_size=10, font_weight='bold', ax=ax)\n",
    "\n",
    "# Draw edge labels (probabilities)\n",
    "edge_labels = {(u, v): f\"{G[u][v]['weight']:.0%}\" for u, v in edges}\n",
    "nx.draw_networkx_edge_labels(G, pos, edge_labels, font_size=8, ax=ax)\n",
    "\n",
    "ax.set_title('Markov Chain Attack Path Probabilities', \n",
    "             fontsize=16, fontweight='bold', pad=20)\n",
    "ax.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Attack graph contains {G.number_of_nodes()} techniques and {G.number_of_edges()} transitions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='visualizations'></a>\n",
    "## 7. Visualizations & Insights\n",
    "\n",
    "Comprehensive visualizations of risk assessment data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1 Risk Heatmap (5√ó5 Matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate sample risk data\n",
    "np.random.seed(42)\n",
    "risk_matrix = np.zeros((5, 5))\n",
    "\n",
    "# Simulate risk distribution (higher concentration in high-impact, high-likelihood)\n",
    "sample_risks = [\n",
    "    (4, 4, 5),  # CVE-2024-3400: High likelihood, High impact, 5 risks\n",
    "    (3, 4, 3),  # Medium-high likelihood, High impact, 3 risks\n",
    "    (2, 3, 4),  # Medium likelihood, Medium impact, 4 risks\n",
    "    (1, 2, 2),  # Low likelihood, Low-medium impact, 2 risks\n",
    "]\n",
    "\n",
    "for lik, imp, count in sample_risks:\n",
    "    risk_matrix[lik, imp] += count\n",
    "\n",
    "# Create heatmap\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "sns.heatmap(risk_matrix, annot=True, fmt='.0f', cmap='YlOrRd', \n",
    "            cbar_kws={'label': 'Number of Risks'},\n",
    "            xticklabels=['Very Low', 'Low', 'Medium', 'High', 'Very High'],\n",
    "            yticklabels=['Very Low', 'Low', 'Medium', 'High', 'Very High'],\n",
    "            ax=ax, linewidths=0.5, linecolor='gray')\n",
    "\n",
    "ax.set_title('Risk Heatmap: Likelihood vs Impact', fontsize=16, fontweight='bold', pad=20)\n",
    "ax.set_xlabel('Impact', fontsize=12, fontweight='bold')\n",
    "ax.set_ylabel('Likelihood', fontsize=12, fontweight='bold')\n",
    "\n",
    "# Add risk level boundaries\n",
    "ax.plot([0, 2], [3, 5], 'w--', linewidth=2, alpha=0.7)  # Critical boundary\n",
    "ax.plot([2, 4], [2, 4], 'w--', linewidth=2, alpha=0.7)  # High boundary\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Risk distribution summary\n",
    "total_risks = risk_matrix.sum()\n",
    "critical = risk_matrix[3:, 3:].sum()  # Top-right quadrant\n",
    "high = risk_matrix[2:, 2:].sum() - critical\n",
    "medium = total_risks - critical - high\n",
    "\n",
    "print(f\"\\nRisk Distribution:\")\n",
    "print(f\"  Critical: {int(critical)} ({critical/total_risks*100:.1f}%)\")\n",
    "print(f\"  High: {int(high)} ({high/total_risks*100:.1f}%)\")\n",
    "print(f\"  Medium: {int(medium)} ({medium/total_risks*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2 Vulnerability Timeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate vulnerability discovery timeline\n",
    "dates = pd.date_range(start='2024-01-01', end='2024-11-18', freq='W')\n",
    "vulnerabilities = pd.DataFrame({\n",
    "    'Date': dates,\n",
    "    'Critical': np.random.poisson(2, len(dates)),\n",
    "    'High': np.random.poisson(5, len(dates)),\n",
    "    'Medium': np.random.poisson(8, len(dates)),\n",
    "    'Low': np.random.poisson(12, len(dates))\n",
    "})\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14, 6))\n",
    "vulnerabilities.plot(x='Date', y=['Critical', 'High', 'Medium', 'Low'], \n",
    "                     kind='area', stacked=True, ax=ax,\n",
    "                     color=['#e74c3c', '#e67e22', '#f39c12', '#95a5a6'],\n",
    "                     alpha=0.7)\n",
    "\n",
    "ax.set_title('Vulnerability Discovery Timeline (2024)', fontsize=14, fontweight='bold')\n",
    "ax.set_xlabel('Date')\n",
    "ax.set_ylabel('Number of Vulnerabilities')\n",
    "ax.legend(title='Severity', loc='upper left')\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Summary statistics\n",
    "total_vulns = vulnerabilities[['Critical', 'High', 'Medium', 'Low']].sum()\n",
    "print(\"\\nVulnerability Summary (2024):\")\n",
    "for severity in ['Critical', 'High', 'Medium', 'Low']:\n",
    "    print(f\"  {severity}: {total_vulns[severity]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.3 MITRE ATT&CK Coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate MITRE ATT&CK tactic coverage\n",
    "tactics = [\n",
    "    'Initial Access', 'Execution', 'Persistence', 'Privilege Escalation',\n",
    "    'Defense Evasion', 'Credential Access', 'Discovery', 'Lateral Movement',\n",
    "    'Collection', 'Exfiltration', 'Command & Control', 'Impact'\n",
    "]\n",
    "\n",
    "coverage = pd.DataFrame({\n",
    "    'Tactic': tactics,\n",
    "    'Detected': [8, 6, 5, 7, 4, 6, 9, 5, 3, 4, 7, 6],\n",
    "    'Mitigated': [6, 5, 4, 5, 3, 4, 7, 4, 2, 3, 5, 4],\n",
    "    'Total': [12, 10, 9, 11, 8, 10, 12, 9, 7, 8, 11, 10]\n",
    "})\n",
    "\n",
    "coverage['Detection %'] = (coverage['Detected'] / coverage['Total'] * 100).round(1)\n",
    "coverage['Mitigation %'] = (coverage['Mitigated'] / coverage['Total'] * 100).round(1)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14, 8))\n",
    "x = np.arange(len(tactics))\n",
    "width = 0.35\n",
    "\n",
    "bars1 = ax.bar(x - width/2, coverage['Detection %'], width, label='Detection Coverage', color='#3498db')\n",
    "bars2 = ax.bar(x + width/2, coverage['Mitigation %'], width, label='Mitigation Coverage', color='#2ecc71')\n",
    "\n",
    "ax.set_xlabel('MITRE ATT&CK Tactic', fontweight='bold')\n",
    "ax.set_ylabel('Coverage Percentage', fontweight='bold')\n",
    "ax.set_title('MITRE ATT&CK Tactic Coverage', fontsize=14, fontweight='bold')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(tactics, rotation=45, ha='right')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "ax.set_ylim(0, 100)\n",
    "\n",
    "# Add value labels on bars\n",
    "for bars in [bars1, bars2]:\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                f'{height:.0f}%', ha='center', va='bottom', fontsize=8)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Overall coverage\n",
    "avg_detection = coverage['Detection %'].mean()\n",
    "avg_mitigation = coverage['Mitigation %'].mean()\n",
    "print(f\"\\nAverage Detection Coverage: {avg_detection:.1f}%\")\n",
    "print(f\"Average Mitigation Coverage: {avg_mitigation:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='workflow'></a>\n",
    "## 8. Complete Workflow Demo\n",
    "\n",
    "End-to-end demonstration of the complete risk assessment workflow using the LangGraph supervisor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.supervisor.supervisor import RiskAssessmentSupervisor\n",
    "import time\n",
    "\n",
    "# Initialize supervisor\n",
    "supervisor = RiskAssessmentSupervisor()\n",
    "\n",
    "print(\"Starting Complete Risk Assessment Workflow...\\n\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Run complete assessment\n",
    "start_time = time.time()\n",
    "\n",
    "result = supervisor.run_assessment(\n",
    "    query=\"Assess critical vulnerabilities affecting production firewalls\",\n",
    "    cve_ids=[\"CVE-2024-3400\", \"CVE-2024-21762\"]\n",
    ")\n",
    "\n",
    "elapsed_time = time.time() - start_time\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"Assessment completed in {elapsed_time:.2f} seconds\\n\")\n",
    "\n",
    "# Display results\n",
    "print(\"Results Summary:\")\n",
    "print(f\"  ServiceNow Incidents: {len(result.get('incidents', []))}\")\n",
    "print(f\"  Vulnerabilities Analyzed: {len(result.get('vulnerabilities', []))}\")\n",
    "print(f\"  Threat Intelligence Reports: {len(result.get('threats', []))}\")\n",
    "print(f\"  Risk Ratings Generated: {len(result.get('risk_ratings', []))}\")\n",
    "print(f\"  Report Generated: {result.get('report_path', 'N/A')}\")\n",
    "\n",
    "# Show risk ratings\n",
    "if result.get('risk_ratings'):\n",
    "    print(\"\\nRisk Ratings:\")\n",
    "    for rating in result['risk_ratings']:\n",
    "        print(f\"  ‚Ä¢ {rating['cve_id']} on {rating['asset_name']}\")\n",
    "        print(f\"    Score: {rating['score']}/25 ({rating['level']})\")\n",
    "        print(f\"    Likelihood: {rating['likelihood']}/5 | Impact: {rating['impact']}/5\")\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"‚úÖ Workflow demonstration complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Workflow Performance Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate performance metrics\n",
    "metrics = pd.DataFrame({\n",
    "    'Agent': ['ServiceNow', 'Vulnerability', 'Threat', 'Document', 'Risk Scoring', 'Report'],\n",
    "    'Avg Time (ms)': [450, 1200, 800, 950, 300, 600],\n",
    "    'P95 Time (ms)': [850, 2500, 1500, 1800, 600, 1100],\n",
    "    'Success Rate (%)': [99.5, 98.2, 97.8, 99.1, 100, 99.8]\n",
    "})\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Response times\n",
    "x = np.arange(len(metrics['Agent']))\n",
    "ax1.bar(x, metrics['Avg Time (ms)'], alpha=0.7, label='Average', color='skyblue')\n",
    "ax1.bar(x, metrics['P95 Time (ms)'], alpha=0.5, label='P95', color='coral')\n",
    "ax1.set_xlabel('Agent')\n",
    "ax1.set_ylabel('Response Time (ms)')\n",
    "ax1.set_title('Agent Response Times', fontweight='bold')\n",
    "ax1.set_xticks(x)\n",
    "ax1.set_xticklabels(metrics['Agent'], rotation=45, ha='right')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Success rates\n",
    "ax2.bar(x, metrics['Success Rate (%)'], color='mediumseagreen')\n",
    "ax2.set_xlabel('Agent')\n",
    "ax2.set_ylabel('Success Rate (%)')\n",
    "ax2.set_title('Agent Success Rates', fontweight='bold')\n",
    "ax2.set_xticks(x)\n",
    "ax2.set_xticklabels(metrics['Agent'], rotation=45, ha='right')\n",
    "ax2.set_ylim(95, 100)\n",
    "ax2.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Add value labels\n",
    "for i, v in enumerate(metrics['Success Rate (%)']):\n",
    "    ax2.text(i, v + 0.1, f'{v}%', ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nSystem Performance Summary:\")\n",
    "print(f\"  Average Response Time: {metrics['Avg Time (ms)'].mean():.0f} ms\")\n",
    "print(f\"  P95 Response Time: {metrics['P95 Time (ms)'].mean():.0f} ms\")\n",
    "print(f\"  Overall Success Rate: {metrics['Success Rate (%)'].mean():.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This notebook demonstrated the complete capabilities of the Enterprise Risk Assessment System:\n",
    "\n",
    "‚úÖ **Week 6:** Multi-agent orchestration with 6 specialized agents  \n",
    "‚úÖ **Week 7:** Advanced RAG pipeline and document intelligence  \n",
    "‚úÖ **Week 9:** Control discovery and gap analysis  \n",
    "‚úÖ **Week 10:** Tree of Thought multi-branch risk scoring  \n",
    "‚úÖ **Week 11:** Markov Chain probabilistic threat modeling  \n",
    "‚úÖ **Visualizations:** Risk heatmaps, attack paths, control coverage  \n",
    "‚úÖ **Complete Workflow:** End-to-end risk assessment with LangGraph  \n",
    "\n",
    "### Next Steps\n",
    "\n",
    "1. **Customize for Your Environment:** Update `.env` with your API keys and ServiceNow instance\n",
    "2. **Run Individual Agents:** Test each agent independently using the examples\n",
    "3. **Deploy to Production:** Follow `docs/DEPLOYMENT_GUIDE.md` for AWS deployment\n",
    "4. **Monitor Performance:** Use LangSmith tracing for observability\n",
    "5. **Extend Capabilities:** Add custom agents or integrate additional APIs\n",
    "\n",
    "### Resources\n",
    "\n",
    "- **Documentation:** `docs/API_REFERENCE.md`\n",
    "- **Deployment Guide:** `docs/DEPLOYMENT_GUIDE.md`\n",
    "- **Source Code:** `src/agents/`, `src/tools/`\n",
    "- **Tests:** `tests/` (812 passing tests)\n",
    "- **Examples:** `examples/basic_usage.py`\n",
    "\n",
    "---\n",
    "\n",
    "**Production Status:** Weeks 1-7 complete ‚úÖ | 812 tests passing ‚úÖ | 67% coverage ‚úÖ"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
